

<!--
## Hi there üëã
**JimmyAwoe/JimmyAwoe** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
<img src="https://{{Your-Image-Link-Here-Optional-e.g.-GitHub-Avatar}}" width="150" alt="Profile Picture"/>

## üî• GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username={{Your-GitHub-Username}}&show_icons=true&theme=vue-dark&hide_border=true&count_private=true" alt="Your GitHub Stats" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username={{Your-GitHub-Username}}&layout=compact&theme=vue-dark&hide_border=true" alt="Your Top Languages" />
</p>

---
-->
<div align="center">
  
  <h1>üëã Hello there! I'm JimmyAwoe </h1>
  <p>
 Enthusiast in Large Models & AI
  </p>¬† 
  
  [![GitHub Followers](https://img.shields.io/github/followers/{{Your-GitHub-Username}}?style=social)](https://github.com/{{Your-GitHub-Username}}?tab=followers)
  [![LinkedIn](https://img.shields.io/badge/-LinkedIn-blue?style=flat-square&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/{{Your-LinkedIn-ID}}/)
  [![Twitter](https://img.shields.io/badge/-Twitter-1DA1F2?style=flat-square&logo=twitter&logoColor=white)](https://twitter.com/{{Your-Twitter-ID-Optional}}/)
  [![Email](https://img.shields.io/badge/-Email-D14836?style=flat-square&logo=gmail&logoColor=white)](mailto:{{Your-Email-Address}})

  ---
</div>

## üí° About Me

I am a second-year Master's student at Peking University.

* üî≠ &nbsp; **Currently Researching:** Efficient and Effective LLM Pretraining & Fine-Tuning Method.


## üõ†Ô∏è Tech Stack & Expertise

| Area | Technologies / Skills |
| :--- | :--- |
| **Deep Learning** | Efficient Pre-training and Fine-tuning of Large Language Models |
| **Programming** | Python |
| **Frameworks** | Megatron-LM, transformers |

---

## üî¨ Featured Research Projects

These are my key contributions to the field of efficient LLM training.
<!--
### GROUTER: Preemptive Routing for Stable and Efficient Mixture-of-Experts Training
* **Core Problem:** Systematically identified and provided a theoretical analysis of **Structure-Performance Interference (SPI)**‚Äîthe inherent instability and optimization error accumulation caused by dynamic routing decisions in MoE training.
* **Innovation:** Proposed **GROUTER**, the first preemptive routing framework designed to *eliminate* SPI. We employ **Knowledge Distillation (KD)** to extract a high-quality, stable routing prior from a well-converged source model, injecting it as a fixed, near-optimal router into the target model.
* **Methodology:** Engineered two novel, complementary strategies for structural migration: **Expert Folding** and **Expert Tuning**.
* **Impact & Results:** Accelerated pre-training data utilization by **4.28x** and achieved up to **33.5% training throughput acceleration**.
-->
### An Efficient Subspace Algorithm for Federated Learning on Heterogeneous Data
* **Core Problem:** Addressed the dual challenge in Federated Learning: severe communication bottlenecks and detrimental client drift caused by Non-IID data.
* **Innovation:** Developed **FedSub**, an efficient subspace federated optimization algorithm that fundamentally enhances communication efficiency and convergence stability.
* **Technical Breakthroughs:** Utilized low-dimensional projection for model update compression (O(md) $\to$ O(rd)) and introduced a **dual variable correction mechanism** to mitigate client drift.
* **Validation:** Achieved comparable convergence accuracy to full-dimension methods at a **50% compression rate**, demonstrating superior convergence speed over established baselines.
* **Implementation** The algorithm has been adapted within my FedSub repository. This repository not only details how to reproduce the main experiments but also includes a packaged implementation of the algorithm. You can refer to the Readme.md to learn how to apply the FedSub algorithm to your own training tasks.

---

